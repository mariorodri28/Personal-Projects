# -*- coding: utf-8 -*-
"""ClasificaciónConvolucional

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/10YT76xT40BXcIe_osJLjfD81eM_LYMTF
"""

import tensorflow as tf
import tensorflow_datasets as tfds

datos, metadatos = tfds.load('fashion_mnist', as_supervised=True, with_info=True)

datos_entrenamiento, datos_pruebas = datos['train'], datos['test']

#Normalizar datos por px
def normalizar(imagenes, etiquetas):
  imagenes = tf.cast(imagenes, tf.float32)
  imagenes/=255
  return imagenes, etiquetas

#Aplicar la normalización a los datos de entrenamiento y pruebas
datos_entrenamiento = datos_entrenamiento.map(normalizar)
datos_pruebas = datos_pruebas.map(normalizar)

#Guardar en caché
datos_entrenamiento = datos_entrenamiento.cache
datos_pruebas = datos_pruebas.cache

#Mostrar imágenes

for imagen, etiqueta in datos_entrenamiento.take(1):
  break
imagen = imagen.numpy().reshape((28,28))

import matplotlib.pyplot as plt

plt.figure()
plt.imshow(imagen, cmap = plt.cm.binary)
plt.colorbar()
plt.grid(False)
plt.show()

#Estructura de modelo,

modelo = tf.keras.Sequential([
    tf.keras.layers.Flatten(input_shape=(28,28,1)),#Parecido a convertir una matriz a Array, de manera visual, aplana las entradas
    tf.keras.layers.Dense(50, activation=tf.nn.relu),#Se aplica Relu como función de activación para aseurar los negativos y hacer más eficientes las predicciones
    tf.keras.layers.Dense(50, activation=tf.nn.relu),
    tf.keras.layers.Dense(10, activation=tf.nn.softmax)#Para clasificación
])

#Compilación

modelo.compile(
    optimizer='adam',
    loss=tf.keras.losses.SparseCategoricalCrossentropy(),
    metrics=['accuracy']
)

#Lotes y preferencias de entrenamiento
num_entrenamiento = metadatos.splits["train"].num_examples
num_pruebas = metadatos.splits["test"].num_examples
lote = 32
datos_entrenamiento = datos_entrenamiento.repeat().shuffle(num_entrenamiento).batch(lote)
datos_pruebas = datos_pruebas.batch(lote)#numero de pruebas

import math

#Entrenamiento

historial = modelo.fit(datos_entrenamiento,epochs=5, steps_per_epoch = math.ceil(num_entrenamiento/lote))

#Funcion perdida

plt.xlabel("Epochs")
plt.ylabel("Loss")
plt.plot(historial.history["loss"])

import numpy as np

for imagenes_prueba, etiquetas_prueba in datos_pruebas.take(1):
  imagenes_prueba = imagenes_prueba.numpy()
  etiquetas_prueba = etiquetas_prueba.numpy()

nombres_clases = metadatos.features['label'].names
imagen = imagenes_prueba[18]
imagen = np.array([imagen])
prediccion = modelo.predict(imagen)

print("Prediccion: " + nombres_clases[np.argmax(prediccion[0])])